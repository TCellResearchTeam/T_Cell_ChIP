{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpc_codes_dir = \"/Volumes/Huitian/Projects/T_Cell_ChIP/202012_ChIP/codes_hpc\"\n",
    "\n",
    "#--- Get list of sra files, retrive Run IDs\n",
    "sra_dir = \"/Volumes/Huitian/Projects/T_Cell_ChIP/202012_ChIP/1_SRA_Run_Table_simplified\"\n",
    "sra_files = glob.glob(\"%s/*.csv\"%sra_dir)\n",
    "\n",
    "srr_list = []\n",
    "for file in sra_files:\n",
    "    srr_list += pd.read_csv(file)['Run'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write Hpc script\n",
    "out_file = \"2_0_MACS2\"\n",
    "out_dir = hpc_codes_dir + \"/\" + out_file\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hpc_wkdir = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/1_bowtie2\"\n",
    "hpc_outdir_1 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2\"\n",
    "hpc_outdir_2 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2_broad\"\n",
    "\n",
    "# Remove the ones that failed\n",
    "failed_alignments = \"/Volumes/Huitian/Projects/T_Cell_ChIP/202012_ChIP/codes_hpc/1_0_trim_alignment_flb_check_3/failed_alignments.csv\"\n",
    "failed_srr = pd.read_csv(failed_alignments)['Run'].tolist()\n",
    "failed_srr\n",
    "\n",
    "#--- Loop through all experiments\n",
    "srr_used = []\n",
    "for i in sra_files:\n",
    "    \n",
    "    i_df = pd.read_csv(i)\n",
    "    i_name = i.split(\"/\")[-1].replace(\"_simplified.csv\",\"\")\n",
    "    \n",
    "    testlist = i_df['condition'].tolist() + i_df['name'].tolist() + i_df['Input'].tolist()\n",
    "    if \"input\" in \"_\".join([x for x in testlist if str(x) != \"nan\"]):\n",
    "        print(i, \"input error\")\n",
    "    \n",
    "    i_df['sample_type'] = [x[:-2] for x in i_df['name']]\n",
    "    i_sp_types = list(set(i_df['sample_type'].tolist()))\n",
    "    i_sp_types = [x for x in i_sp_types if \"Input\" not in x]\n",
    "\n",
    "    #####---------- Write one script for each sample condition\n",
    "    # -t treatmentfile\n",
    "    # -c control\n",
    "    # -n name\n",
    "    # -g genome\n",
    "    # -B --SPMR generate pileup signal file of 'fragment \n",
    "    #            pileup per million reads' in bedGraph format.\n",
    "    # --nomodel bypass building the shifting model\n",
    "    # --extsize extend reads in 5'->3' direction to fix-sized \n",
    "    #           fragments when nomodel is on\n",
    "    # --outdir save output fiels to specified folder\n",
    "    # --broad  composite broad regions in BED12 (a gene-model-like \n",
    "    #          format) by putting nearby highly enriched regions \n",
    "    #          into a broad region with loose cutoff.\n",
    "\n",
    "    for sp_type in i_sp_types:\n",
    "        i_outname = \"%s/%s_%s-%s.sh\"%(out_dir, out_file, i_name, sp_type)\n",
    "\n",
    "        sp_type_df = i_df[i_df['sample_type'] == sp_type]\n",
    "        sp_srr = sp_type_df['Run'].tolist()\n",
    "        sp_name = sp_type_df['condition'].tolist()[0]\n",
    "\n",
    "        sp_input = sp_type_df['Input'].tolist()[0]\n",
    "        if sp_input != \"\":\n",
    "            sp_input_df = i_df[i_df['sample_type'] == sp_input]\n",
    "            sp_input_srr = sp_input_df['Run'].tolist()\n",
    "        else:\n",
    "            sp_input_srr = []\n",
    "\n",
    "        sp_srr = [x for x in sp_srr if x not in failed_srr]\n",
    "        sp_input_srr = [x for x in sp_input_srr if x not in failed_srr]\n",
    "        srr_used += sp_srr\n",
    "        srr_used += sp_input_srr\n",
    "\n",
    "        sp_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_srr]\n",
    "        sp_input_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_input_srr]\n",
    "        sp_bam_str = \" \".join(sp_bam_files)\n",
    "        sp_input_bam_str = \" \".join(sp_input_bam_files)\n",
    "        \n",
    "        # Proceed if the experiment file is okay\n",
    "        if len(sp_srr) > 0:\n",
    "            with open(i_outname, \"w\") as fout:\n",
    "                wfout = csv.writer(fout, delimiter=\"\\t\",lineterminator='\\n')\n",
    "                wfout.writerow([\"#!/bin/bash\"])\n",
    "                wfout.writerow([\"#SBATCH --mem=24gb\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"module load macs/2.1.0\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"BAM_INPUT_DIR=%s\"%hpc_wkdir])\n",
    "                wfout.writerow([\"OUT_DIR1=%s\"%hpc_outdir_1])\n",
    "                wfout.writerow([\"OUT_DIR2=%s\"%hpc_outdir_2])\n",
    "                wfout.writerow([\"cd $BAM_INPUT_DIR\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"########## Peak calling\"])\n",
    "                if len(sp_input_srr) > 0:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                    %(sp_bam_str, sp_input_bam_str)])\n",
    "                else:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                    %(sp_bam_str)])\n",
    "                wfout.writerow([\"               -g mm -B --SPMR --nomodel --extsize 147 --call-summits \\\\\"])\n",
    "                wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR1\"%(i_name, sp_name)])\n",
    "\n",
    "                if sp_type.startswith(\"H3\"):\n",
    "                    wfout.writerow([])\n",
    "                    if len(sp_input_srr) > 0:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                        %(sp_bam_str, sp_input_bam_str)])\n",
    "                    else:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                        %(sp_bam_str)])\n",
    "                    wfout.writerow([\"               -g mm --nomodel --extsize 147 --broad \\\\\"])\n",
    "                    wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR2\"%(i_name, sp_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(srr_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(srr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
