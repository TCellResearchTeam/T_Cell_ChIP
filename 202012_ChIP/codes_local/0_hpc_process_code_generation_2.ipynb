{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    code_dir\n",
    "except NameError:\n",
    "    code_dir = os.getcwd()\n",
    "    hpc_codes_dir = code_dir.replace(\"codes_local\", \"codes_hpc\")\n",
    "    sra_dir = code_dir.replace(\"codes_local\", \"1_SRA_Run_Table_simplified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACS2 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Get list of sra files, retrive Run IDs\n",
    "sra_files = glob.glob(\"%s/*.csv\"%sra_dir)\n",
    "\n",
    "srr_list = []\n",
    "for file in sra_files:\n",
    "    srr_list += pd.read_csv(file)['Run'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write Hpc script\n",
    "out_file = \"2_0_MACS2\"\n",
    "out_dir = hpc_codes_dir + \"/\" + out_file\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hpc_wkdir = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/1_bowtie2\"\n",
    "hpc_outdir_1 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2\"\n",
    "hpc_outdir_2 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2_broad\"\n",
    "\n",
    "# Remove the ones that failed\n",
    "failed_alignments = \"/Volumes/Huitian/Projects/T_Cell_ChIP/202012_ChIP/codes_hpc/1_0_trim_alignment_flb_check_3/failed_alignments.csv\"\n",
    "failed_srr = pd.read_csv(failed_alignments)['Run'].tolist()\n",
    "failed_srr\n",
    "\n",
    "#--- Loop through all experiments\n",
    "srr_used = []\n",
    "for i in sra_files:\n",
    "    \n",
    "    i_df = pd.read_csv(i)\n",
    "    i_name = i.split(\"/\")[-1].replace(\"_simplified.csv\",\"\")\n",
    "    \n",
    "    testlist = i_df['condition'].tolist() + i_df['name'].tolist() + i_df['Input'].tolist()\n",
    "    if \"input\" in \"_\".join([x for x in testlist if str(x) != \"nan\"]):\n",
    "        print(i, \"input error\")\n",
    "    \n",
    "    i_df['sample_type'] = [x[:-2] for x in i_df['name']]\n",
    "    i_sp_types = list(set(i_df['sample_type'].tolist()))\n",
    "    i_sp_types = [x for x in i_sp_types if \"Input\" not in x]\n",
    "\n",
    "    #####---------- Write one script for each sample condition\n",
    "    # -t treatmentfile\n",
    "    # -c control\n",
    "    # -n name\n",
    "    # -g genome\n",
    "    # -B --SPMR generate pileup signal file of 'fragment \n",
    "    #            pileup per million reads' in bedGraph format.\n",
    "    # --nomodel bypass building the shifting model\n",
    "    # --extsize extend reads in 5'->3' direction to fix-sized \n",
    "    #           fragments when nomodel is on\n",
    "    # --outdir save output fiels to specified folder\n",
    "    # --broad  composite broad regions in BED12 (a gene-model-like \n",
    "    #          format) by putting nearby highly enriched regions \n",
    "    #          into a broad region with loose cutoff.\n",
    "\n",
    "    for sp_type in i_sp_types:\n",
    "        i_outname = \"%s/%s_%s-%s.sh\"%(out_dir, out_file, i_name, sp_type)\n",
    "\n",
    "        sp_type_df = i_df[i_df['sample_type'] == sp_type]\n",
    "        sp_srr = sp_type_df['Run'].tolist()\n",
    "        sp_name = sp_type_df['condition'].tolist()[0]\n",
    "\n",
    "        sp_input = sp_type_df['Input'].tolist()[0]\n",
    "        if sp_input != \"\":\n",
    "            sp_input_df = i_df[i_df['sample_type'] == sp_input]\n",
    "            sp_input_srr = sp_input_df['Run'].tolist()\n",
    "        else:\n",
    "            sp_input_srr = []\n",
    "\n",
    "        sp_srr = [x for x in sp_srr if x not in failed_srr]\n",
    "        sp_input_srr = [x for x in sp_input_srr if x not in failed_srr]\n",
    "        srr_used += sp_srr\n",
    "        srr_used += sp_input_srr\n",
    "\n",
    "        sp_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_srr]\n",
    "        sp_input_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_input_srr]\n",
    "        sp_bam_str = \" \".join(sp_bam_files)\n",
    "        sp_input_bam_str = \" \".join(sp_input_bam_files)\n",
    "        \n",
    "        # Proceed if the experiment file is okay\n",
    "        if len(sp_srr) > 0:\n",
    "            with open(i_outname, \"w\") as fout:\n",
    "                wfout = csv.writer(fout, delimiter=\"\\t\",lineterminator='\\n')\n",
    "                wfout.writerow([\"#!/bin/bash\"])\n",
    "                wfout.writerow([\"#SBATCH --mem=24gb\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"module load macs/2.1.0\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"BAM_INPUT_DIR=%s\"%hpc_wkdir])\n",
    "                wfout.writerow([\"OUT_DIR1=%s\"%hpc_outdir_1])\n",
    "                wfout.writerow([\"OUT_DIR2=%s\"%hpc_outdir_2])\n",
    "                wfout.writerow([\"cd $BAM_INPUT_DIR\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"########## Peak calling\"])\n",
    "                if len(sp_input_srr) > 0:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                    %(sp_bam_str, sp_input_bam_str)])\n",
    "                else:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                    %(sp_bam_str)])\n",
    "                wfout.writerow([\"               -g mm -B --SPMR --nomodel --extsize 147 --call-summits \\\\\"])\n",
    "                wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR1\"%(i_name, sp_name)])\n",
    "\n",
    "                if sp_type.startswith(\"H3\"):\n",
    "                    wfout.writerow([])\n",
    "                    if len(sp_input_srr) > 0:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                        %(sp_bam_str, sp_input_bam_str)])\n",
    "                    else:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                        %(sp_bam_str)])\n",
    "                    wfout.writerow([\"               -g mm --nomodel --extsize 147 --broad \\\\\"])\n",
    "                    wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR2\"%(i_name, sp_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MACS2 codes for Brd4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_files = ['/media/pipkin/Rocket2/T_Cell_ChIP/202012_ChIP/1_SRA_Run_Table_simplified/2021_GoldrathLab_Brd4_simplified.csv']\n",
    "\n",
    "#--- Write Hpc script\n",
    "out_file = \"2_0_MACS2_brd4\"\n",
    "out_dir = hpc_codes_dir + \"/\" + out_file\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hpc_wkdir = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/1_bowtie2\"\n",
    "hpc_outdir_1 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2\"\n",
    "hpc_outdir_2 = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2_broad\"\n",
    "\n",
    "\n",
    "#--- Loop through all experiments\n",
    "srr_used = []\n",
    "for i in sra_files:\n",
    "    \n",
    "    i_df = pd.read_csv(i)\n",
    "    i_name = i.split(\"/\")[-1].replace(\"_simplified.csv\",\"\")\n",
    "    \n",
    "    testlist = i_df['condition'].tolist() + i_df['name'].tolist() + i_df['Input'].tolist()\n",
    "    if \"input\" in \"_\".join([x for x in testlist if str(x) != \"nan\"]):\n",
    "        print(i, \"input error\")\n",
    "    \n",
    "    i_df['sample_type'] = [x[:-2] for x in i_df['name']]\n",
    "    i_sp_types = list(set(i_df['sample_type'].tolist()))\n",
    "    i_sp_types = [x for x in i_sp_types if \"Input\" not in x]\n",
    "\n",
    "    #####---------- Write one script for each sample condition\n",
    "    # -t treatmentfile\n",
    "    # -c control\n",
    "    # -n name\n",
    "    # -g genome\n",
    "    # -B --SPMR generate pileup signal file of 'fragment \n",
    "    #            pileup per million reads' in bedGraph format.\n",
    "    # --nomodel bypass building the shifting model\n",
    "    # --extsize extend reads in 5'->3' direction to fix-sized \n",
    "    #           fragments when nomodel is on\n",
    "    # --outdir save output fiels to specified folder\n",
    "    # --broad  composite broad regions in BED12 (a gene-model-like \n",
    "    #          format) by putting nearby highly enriched regions \n",
    "    #          into a broad region with loose cutoff.\n",
    "\n",
    "    for sp_type in i_sp_types:\n",
    "        i_outname = \"%s/%s_%s-%s.sh\"%(out_dir, out_file, i_name, sp_type)\n",
    "\n",
    "        sp_type_df = i_df[i_df['sample_type'] == sp_type]\n",
    "        sp_srr = sp_type_df['Run'].tolist()\n",
    "        sp_name = sp_type_df['condition'].tolist()[0]\n",
    "\n",
    "        sp_input = sp_type_df['Input'].tolist()[0]\n",
    "        if sp_input != \"\":\n",
    "            sp_input_df = i_df[i_df['sample_type'] == sp_input]\n",
    "            sp_input_srr = sp_input_df['Run'].tolist()\n",
    "        else:\n",
    "            sp_input_srr = []\n",
    "            \n",
    "        srr_used += sp_srr\n",
    "        srr_used += sp_input_srr\n",
    "\n",
    "        sp_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_srr]\n",
    "        sp_input_bam_files = [\"%s_srt_dupr_flb.bam\"%x for x in sp_input_srr]\n",
    "        sp_bam_str = \" \".join(sp_bam_files)\n",
    "        sp_input_bam_str = \" \".join(sp_input_bam_files)\n",
    "        \n",
    "        # Proceed if the experiment file is okay\n",
    "        if len(sp_srr) > 0:\n",
    "            with open(i_outname, \"w\") as fout:\n",
    "                wfout = csv.writer(fout, delimiter=\"\\t\",lineterminator='\\n')\n",
    "                wfout.writerow([\"#!/bin/bash\"])\n",
    "                wfout.writerow([\"#SBATCH --mem=24gb\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"module load macs/2.1.0\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"BAM_INPUT_DIR=%s\"%hpc_wkdir])\n",
    "                wfout.writerow([\"OUT_DIR1=%s\"%hpc_outdir_1])\n",
    "                wfout.writerow([\"OUT_DIR2=%s\"%hpc_outdir_2])\n",
    "                wfout.writerow([\"cd $BAM_INPUT_DIR\"])\n",
    "                wfout.writerow([])\n",
    "                wfout.writerow([\"########## Peak calling\"])\n",
    "                if len(sp_input_srr) > 0:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                    %(sp_bam_str, sp_input_bam_str)])\n",
    "                else:\n",
    "                    wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                    %(sp_bam_str)])\n",
    "                wfout.writerow([\"               -g mm -B --SPMR --nomodel --extsize 147 --call-summits \\\\\"])\n",
    "                wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR1\"%(i_name, sp_name)])\n",
    "\n",
    "                if sp_type.startswith(\"H3\"):\n",
    "                    wfout.writerow([])\n",
    "                    if len(sp_input_srr) > 0:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s -c %s \\\\\" \n",
    "                                        %(sp_bam_str, sp_input_bam_str)])\n",
    "                    else:\n",
    "                        wfout.writerow([\"macs2 callpeak -t %s \\\\\"\n",
    "                                        %(sp_bam_str)])\n",
    "                    wfout.writerow([\"               -g mm --nomodel --extsize 147 --broad \\\\\"])\n",
    "                    wfout.writerow([\"               -n %s___%s --outdir $OUT_DIR2\"%(i_name, sp_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bedgraph to bigwig codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021_GoldrathLab_Brd4___BRD4_TE-CD8_treat_pileup.bdg',\n",
       " '2021_GoldrathLab_Brd4___BRD4_NAV-CD8_treat_pileup.bdg',\n",
       " '2021_GoldrathLab_Brd4___BRD4_MP-CD8_treat_pileup.bdg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpc_codes_dir = code_dir.replace(\"codes_local\", \"codes_hpc\")\n",
    "\n",
    "macs2_out_dir = \"/media/pipkin/Rocket2/T_Cell_ChIP/202012_ChIP/2_MACS2\"\n",
    "bdg_files = glob.glob(\"%s/*treat_pileup.bdg\"%macs2_out_dir)\n",
    "bdg_files = [x.split(\"/\")[-1] for x in bdg_files]\n",
    "\n",
    "# Redo for Brd4\n",
    "bdg_files = [x for x in bdg_files if \"2021\" in x]\n",
    "bdg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write Hpc script\n",
    "out_file = \"2_1_bedgraph_to_bigwig_brd4\"\n",
    "out_dir = hpc_codes_dir + \"/\" + out_file\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hpc_wkdir = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2\"\n",
    "hpc_outdir = \"/gpfs/group/pipkin/hdiao/T_Cell_ChIP/2_MACS2_bw\"\n",
    "chrom_sizes = \"/gpfs/group/pipkin/hdiao/ref_resources/mm/release102/GRCm38.genome.sizes\"\n",
    "\n",
    "#--- Loop through all experiments\n",
    "for i in bdg_files:\n",
    "    i_name = i.replace('_treat_pileup.bdg', '')\n",
    "    i_outname = \"%s/%s_%s.sh\"%(out_dir, out_file, i_name)\n",
    "    with open(i_outname, \"w\") as fout:\n",
    "        wfout = csv.writer(fout, delimiter=\"\\t\",lineterminator='\\n')\n",
    "        wfout.writerow([\"#!/bin/bash\"])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"module load ucsc_tools\"])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"MACS2_DIR=%s\"%hpc_wkdir])\n",
    "        wfout.writerow([\"OUT_DIR=%s\"%hpc_outdir])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"bdg_name=$MACS2_DIR/%s\"%i])\n",
    "        wfout.writerow([\"bdg_srt_name=$MACS2_DIR/%s\"%i.replace(\".bdg\", \"_srt.bdg\")])\n",
    "        wfout.writerow([\"bw_name=$OUT_DIR/%s\"%i.replace('_treat_pileup.bdg', \".bw\")])\n",
    "        wfout.writerow([\"chrom_size=%s\"%chrom_sizes])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"##### Sort bedgraph file\"])\n",
    "        wfout.writerow([\"LC_COLLATE=C sort -k1,1 -k2,2n $bdg_name > $bdg_srt_name\"])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"##### Convert\"])\n",
    "        wfout.writerow([\"bedGraphToBigWig $bdg_srt_name $chrom_size $bw_name\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
